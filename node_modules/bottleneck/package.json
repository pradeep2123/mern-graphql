{
  "_args": [
    [
      {
        "raw": "bottleneck@^1.12.0",
        "scope": null,
        "escapedName": "bottleneck",
        "name": "bottleneck",
        "rawSpec": "^1.12.0",
        "spec": ">=1.12.0 <2.0.0",
        "type": "range"
      },
      "F:\\react-node\\mern-graphql\\node_modules\\sendgrid"
    ]
  ],
  "_from": "bottleneck@>=1.12.0 <2.0.0",
  "_id": "bottleneck@1.16.0",
  "_inCache": true,
  "_location": "/bottleneck",
  "_nodeVersion": "4.4.7",
  "_npmOperationalInternal": {
    "host": "s3://npm-registry-packages",
    "tmp": "tmp/bottleneck-1.16.0.tgz_1497912417945_0.23726055189035833"
  },
  "_npmUser": {
    "name": "sgrondin",
    "email": "jobs@simongrondin.name"
  },
  "_npmVersion": "2.15.8",
  "_phantomChildren": {},
  "_requested": {
    "raw": "bottleneck@^1.12.0",
    "scope": null,
    "escapedName": "bottleneck",
    "name": "bottleneck",
    "rawSpec": "^1.12.0",
    "spec": ">=1.12.0 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/sendgrid"
  ],
  "_resolved": "https://registry.npmjs.org/bottleneck/-/bottleneck-1.16.0.tgz",
  "_shasum": "d6ce13808527afc80b69092f15606655e5b21f1a",
  "_shrinkwrap": null,
  "_spec": "bottleneck@^1.12.0",
  "_where": "F:\\react-node\\mern-graphql\\node_modules\\sendgrid",
  "author": {
    "name": "Simon Grondin"
  },
  "bugs": {
    "url": "https://github.com/SGrondin/bottleneck/issues"
  },
  "dependencies": {},
  "description": "Async rate limiter",
  "devDependencies": {
    "browserify": "*",
    "coffee-script": "1.11.x",
    "mocha": "*",
    "uglify-js": "*"
  },
  "directories": {},
  "dist": {
    "shasum": "d6ce13808527afc80b69092f15606655e5b21f1a",
    "tarball": "https://registry.npmjs.org/bottleneck/-/bottleneck-1.16.0.tgz"
  },
  "gitHead": "af47014f4daff3f241f987762deba9e074c000f1",
  "homepage": "https://github.com/SGrondin/bottleneck#readme",
  "keywords": [
    "async rate limiter",
    "rate limiter",
    "rate limiting",
    "async",
    "rate",
    "limiting",
    "limiter",
    "throttle",
    "throttling",
    "load",
    "ddos"
  ],
  "license": "MIT",
  "main": "lib/index.js",
  "maintainers": [
    {
      "name": "sgrondin",
      "email": "jobs@simongrondin.name"
    }
  ],
  "name": "bottleneck",
  "optionalDependencies": {},
  "readme": "# bottleneck\n\n[![Downloads][npm-downloads]][npm-url]\n[![version][npm-version]][npm-url]\n[![License][npm-license]][license-url]\n[![Gitter][gitter-image]][gitter-url]\n\nBottleneck is a tiny and efficient Task Scheduler and Rate Limiter for Node.JS and the browser. When dealing with services with limited resources, it's important to ensure that they don't become overloaded.\n\nBottleneck is the easiest solution as it doesn't add much complexity to the code.\n\nIt's battle-hardened, reliable and production-ready. It's used on a large scale in both private companies and open source software.\n\n\n## Install\n\n__Node__\n```\nnpm install bottleneck\n```\n__Browser__\n```\nbower install bottleneck\n```\nor\n```html\n<script type=\"text/javascript\" src=\"bottleneck.min.js\"></script>\n```\n\n\n###### Example\n\nMost APIs have a rate limit. For example, the Reddit.com API limits programs to 1 request every 2 seconds.\n\n```js\nvar Bottleneck = require(\"bottleneck\"); // Skip when browser side\n\n// Never more than 1 request running at a time.\n// Wait at least 2000ms between each request.\nvar limiter = new Bottleneck(1, 2000);\n```\n\nInstead of doing\n```js\nsomeAsyncCall(arg1, arg2, argN, callback);\n```\nYou do\n```js\nlimiter.submit(someAsyncCall, arg1, arg2, argN, callback);\n```\nAnd now you can be assured that someAsyncCall will abide by your rate guidelines!\n\nPromise users can use [`schedule()`](https://github.com/SGrondin/bottleneck#schedule).\n\nBottleneck builds a queue of requests and executes them as soon as possible. All the requests will be executed *in the order that they were received*. See [priorities](https://github.com/SGrondin/bottleneck#priorities) if you wish to alter this behavior.\n\nThis is sufficient for the vast majority of applications. **Read the [Gotchas](https://github.com/SGrondin/bottleneck#gotchas) section** and you're good to go. Or keep reading to learn about all the fine tuning available for the more complex use cases.\n\n\n## Docs\n\n### Constructor\n\n```js\nvar limiter = new Bottleneck(maxConcurrent, minTime, highWater, strategy, rejectOnDrop);\n```\n\n* `maxConcurrent` : How many requests can be running at the same time. *Default: `0` (unlimited)*\n* `minTime` : How long to wait after launching a request before launching another one. *Default: `0`ms*\n* `highWater` : How long can the queue get? *Default: `-1` (unlimited)*\n* `strategy` : Which strategy to use if the queue gets longer than the high water mark. *Default: `Bottleneck.strategy.LEAK`.*\n* `rejectOnDrop` : When `true` if a job is dropped its callback will be called with the first argument set to an `Error` object. If the job was a promise it will be rejected. *Default: `false`*\n\n\n### submit()\n\nAdds a request to the queue.\n\n```js\nlimiter.submit(someAsyncCall, arg1, arg2, argN, callback);\n```\n\nIt returns `true` if the strategy was executed.\n\n\n### schedule()\n\nAdds a request to the queue. This is the Promise version of `submit`. It uses the [bluebird](https://github.com/petkaantonov/bluebird) package if installed and otherwise uses the built-in [Promise](http://caniuse.com/#feat=promises) object.\n\n```js\nvar fn = function(arg1, arg2, argN) {\n\treturn httpGet(arg1, arg2, argN); // Here httpGet() returns a promise\n};\n\nlimiter.schedule(fn, arg1, arg2, argN); // This also returns a promise, for chaining\n```\n\nIn plain language, `schedule` takes a function fn and a list of arguments. Fn must return a promise. `schedule` returns a promise that will be executed according to the rate limits. It's safe to mix `submit` and `schedule` in the same limiter.\n\nHere's another example, this time using the ECMAScript 7 syntax:\n\n```js\n// fn returns a promise\nfunction fn (url) {\n    return http.get(url).then(response => console.log(response.body));\n}\n\nlimiter.schedule(fn, url);\n```\n\nIt's also possible to replace the Promise library used:\n\n```js\nvar Bottleneck = require(\"bottleneck\");\nBottleneck.prototype.Promise = myPromiseLibrary;\n\nvar limiter = new Bottleneck(maxConcurrent, minTime, highWater, strategy, rejectOnDrop);\n```\n\n\n## Gotchas\n\n* When using `submit`, if a callback isn't necessary, you must pass `null` or an empty function instead. It will not work if you forget to do this.\n\n* Make sure that all the requests will eventually complete by calling their callback (or resolving/rejecting in the case of promises). Again, even if you `submit`ted your request with a `null` callback , it still needs to call its callback. This is very important if you are using a `maxConcurrent` value that isn't `0` (unlimited), otherwise those uncompleted requests will be clogging up the limiter and no new requests will be getting through. It's safe to call the callback more than once, subsequent calls are ignored.\n\n* If you want to rate limit a synchronous function (`console.log(), for example), you must wrap it in a closure to make it asynchronous. See [this](https://github.com/SGrondin/bottleneck#rate-limiting-synchronous-functions) example.\n\n\n### Priorities\n\nEvery request has a priority level. It's `5` for every request added with `submit`/`schedule`. There exists a variant of those functions that lets you set the priority of a request.\n\nPriority `0` is the most important and `9` is the least important.\n\n**More important requests will *always* be executed before less important ones. For requests with the same priority level, the oldest one is executed first.**\n\n#### submitPriority()\n\n```js\nlimiter.submitPriority(priority, someAsyncCall, arg1, arg2, argN, cb);\n```\n\n#### schedulePriority()\n\n```js\nlimiter.schedulePriority(priority, fn, arg1, arg2, argN);\n```\n\n\n### Strategies\n\nA strategy is a simple algorithm that is executed every time adding a request would cause the number of queued requests to exceed `highWater`. See [Events](https://github.com/SGrondin/bottleneck#events).\n\n#### Bottleneck.strategy.LEAK\nWhen submitting a new request, if the queue length reaches `highWater`, drop the oldest request with the lowest priority. This is useful when requests that have been waiting for too long are not important anymore. If all the queued up requests are more important than the one being added, it won't be added.\n\n#### Bottleneck.strategy.OVERFLOW_PRIORITY\nSame as `LEAK`, except that it will only drop requests that are *less important* than the one being added. If all the queued up requests are as important or more than the new one, it won't be added.\n\n#### Bottleneck.strategy.OVERFLOW\nWhen submitting a new request, if the queue length reaches `highWater`, do not add the new request. This strategy totally ignores priority levels.\n\n#### Bottleneck.strategy.BLOCK\nWhen submitting a new request, if the queue length reaches `highWater`, the limiter falls into \"blocked mode\". All queued requests are dropped and no new requests will be accepted until the limiter unblocks. It will unblock after `penalty` milliseconds have passed without receiving a new request. `penalty` is equal to `15 * minTime` (or `5000` if `minTime` is `0`) by default and can be changed by calling `changePenalty()`. This strategy is ideal when bruteforce attacks are to be expected. This strategy totally ignores priority levels.\n\n\n### nbQueued()\n\n```js\nlimiter.nbQueued(priority);\n```\n\n`priority` is optional. Without that argument, it'll return the total number of requests waiting to be executed, otherwise it'll only count the number of requests with that specific priority.\n\n### nbRunning()\n\n```js\nlimiter.nbRunning();\n```\n\nReturns the number of requests currently running in the limiter.\n\n### check()\n\n```js\nlimiter.check();\n```\nIf a request was added right now, would it be run immediately? Returns a boolean.\n\n\n### isBlocked()\n\n```js\nlimiter.isBlocked();\n```\nIs the limiter currently in \"blocked mode\"? Returns a boolean.\n\n\n### stopAll()\n\n```js\nlimiter.stopAll(interrupt);\n```\nCancels all *queued up* requests and every added request will be automatically rejected.\n\n* `interrupt` : If true, prevent the requests currently running from calling their callback when they're done. *Default: `false`*\n\n\n### Events\n\nEvent names: `empty`, `idle`, `dropped`.\n\n```js\nlimiter.on('empty', function () {\n  // This will be called when the nbQueued() drops to 0.\n})\n```\n\n```js\nlimiter.on('idle', function () {\n  // This will be called when the nbQueued() drops to 0 AND there is nothing currently running in the limiter.\n})\n```\n\n```js\nlimiter.on('dropped', function (dropped) {\n  // This will be called when a strategy was triggered.\n  // The dropped request is passed to this callback.\n})\n```\n\nUse `removeAllListeners()` with an optional event name as first argument to remove listeners.\n\n**Note:** It's possible to set multiple callbacks to the same event name.\n\n\n### changeSettings()\n\n```js\nlimiter.changeSettings(maxConcurrent, minTime, highWater, strategy);\n```\nSame parameters as the constructor, pass ```null``` to skip a parameter and keep it to its current value.\n\n**Note:** Changing `maxConcurrent` and `minTime` will not affect requests that have already been scheduled for execution.\n\nFor example, imagine that three 60-second requests are submitted at time T with `maxConcurrent = 0` and `minTime = 2000`. The requests will be launched at T seconds, T+2 seconds and T+4 seconds respectively. If right after adding the requests to Bottleneck, you were to call `limiter.changeSettings(1);`, it won't change the fact that there will be 3 requests running at the same time for roughly 60 seconds. Once again, `changeSettings` only affects requests that have not yet been added.\n\nThis is by design, as Bottleneck made a promise to execute those requests according to the settings valid at the time. Changing settings afterwards should not break previous assumptions, as that would make code very error-prone and Bottleneck a tool that cannot be relied upon.\n\n\n### changePenalty()\n\n```js\nlimiter.changePenalty(penalty);\n```\nThis changes the `penalty` value used by the `BLOCK` strategy.\n\n\n### changeReservoir(), incrementReservoir()\n\n```js\nlimiter.changeReservoir(reservoir);\n\nlimiter.incrementReservoir(incrementBy);\n```\n* `reservoir` : How many requests can be executed before the limiter stops executing requests. *Default: `null` (unlimited)*\n\nIf `reservoir` reaches `0`, no new requests will be executed until it is no more `0`\n\n\n### chain()\n\n* `limiter` : If another limiter is passed, tasks that are ready to be executed will be added to that other limiter. *Default: `null` (none)*\n\nSuppose you have 2 types of tasks, A and B. They both have their own limiter with their own settings, but both must also follow a global limiter C:\n```js\nvar limiterA = new Bottleneck(...some settings...);\nvar limiterB = new Bottleneck(...some different settings...);\nvar limiterC = new Bottleneck(...some global settings...);\nlimiterA.chain(limiterC);\nlimiterB.chain(limiterC);\n// Requests added to limiterA must follow the A and C rate limits.\n// Requests added to limiterB must follow the B and C rate limits.\n// Requests added to limiterC must follow the C rate limits.\n```\n\n\n## Execution guarantee\n\nBottleneck will execute every request in order of priority first, oldest to youngest within each priority level. You can be certain that they will **all** *eventually* be executed as long as:\n\n* `highWater` is set to `-1` (default), which prevents the strategy from ever being run **OR** you never exceed the `highWater`.\n* `maxConcurrent` is set to `0` (default) **OR** all requests call the callback *eventually* (in the case of promises, they must be resolved or rejected eventually).\n* `reservoir` is `null` (default).\n\n\n## Cluster\n\nThe `Cluster` feature of Bottleneck manages many limiters automatically for you. It creates limiters dynamically and transparently.\n\nLet's take a DNS server as an example of how Bottleneck can be used. It's a service that sees a lot of abuse and where incoming DNS requests need to be rate limited. Bottleneck is so tiny, it's perfectly fine to create one limiter for each origin IP, even if it means creating thousands and thousands of limiters. The `Cluster` mode is perfect for this use case. We can create one cluster and then use the origin IP to rate limit each IP independently. Each call with the same key will be routed to the same underlying limiter. A cluster is created exactly like a limiter:\n\n\n```js\nvar cluster = new Bottleneck.Cluster(maxConcurrent, minTime, highWater, strategy);\n```\n\nThe cluster is then used with the `.key(str)` method:\n\n```js\n// In this example, the key is an IP\ncluster.key(\"77.66.54.32\").submit(someAsyncCall, arg1, arg2, cb);\n```\n\n\n### key()\n\n* `str` : The key to use. All calls submitted with the same key will use the same limiter. *Default: `\"\"`*\n\nThe return value of `.key(str)` is a limiter. If it doesn't already exist, it is created on the fly. Limiters that have been idle for a long time are deleted to avoid memory leaks.\n\n\n### stopAutoCleanup()\n\nCalling `stopAutoCleanup()` on a cluster will turn off its garbage collection, so limiters for keys that have not been used in over **5 minutes** will NOT be deleted anymore. It can be reenabled by calling `startAutoCleanup()`. The `5 minutes` figure can be modified by calling `changeTimeout()`.\n\n\n### startAutoCleanup()\n\nReactivate the cluster's garbage collection for limiters (in the cluster) that have been inactive for over 5 minutes.\n\n### changeTimeout()\n\n* `timeout`: The expiration time for unused limiters, in milliseconds. By default it is `300000` (5 minutes).\n\nWhen autocleanup is enabled, limiters having not been used in the last `timeout` milliseconds will be deleted to avoid memory leaks.\n\n\n### deleteKey()\n\n* `str`: The key for the limiter to delete.\n\nManually deletes the limiter at the specified key. This can be useful when the auto cleanup is turned off.\n\n\n### all()\n\n* `cb` : A function to be executed on every limiter in the cluster.\n\nFor example, this will call `stopAll()` on every limiter in the cluster:\n\n```javasript\ncluster.all(function(limiter){\n  limiter.stopAll();\n});\n```\n\n\n### keys()\n\nReturns an array containing all the keys in the cluster.\n\n\n## Rate-limiting synchronous functions\n\nMost of the time, using Bottleneck is as simple as the first example above. However, when Bottleneck is used on a synchronous call, it (obviously) becomes asynchronous, so the returned value of that call can't be used directly. The following example should make it clear why.\n\nThis is the original code that we want to rate-limit:\n```js\nvar req = http.request(options, function(res){\n  //do stuff with res\n});\nreq.write(\"some string\", \"utf8\");\nreq.end();\n```\n\nThe following code snippet will **NOT** work, because `http.request` is not executed synchronously therefore `req` doesn't contain the expected request object.\n```js\n// DOES NOT WORK\nvar req = limiter.submit(http.request, options, function(res){\n  //do stuff with res\n});\nreq.write(\"some string\", \"utf8\");\nreq.end();\n```\n\nThis is the right way to do it:\n```js\nlimiter.submit(function(cb){\n  var req = http.request(options, function(res){\n    //do stuff with res\n    cb();\n  });\n  req.write(\"some string\", \"utf8\");\n  req.end();\n}, null);\n```\n\n\n## Contributing\n\nThis README file is always in need of better explanations and examples. If things can be clearer and simpler, please consider forking this repo and submitting a Pull Request, or simply open an issue.\n\nSuggestions and bug reports are also welcome.\n\n[license-url]: https://github.com/SGrondin/bottleneck/blob/master/LICENSE\n\n[npm-url]: https://www.npmjs.com/package/bottleneck\n[npm-license]: https://img.shields.io/npm/l/bottleneck.svg?style=flat\n[npm-version]: https://img.shields.io/npm/v/bottleneck.svg?style=flat\n[npm-downloads]: https://img.shields.io/npm/dm/bottleneck.svg?style=flat\n\n[gitter-url]: https://gitter.im/SGrondin/bottleneck\n[gitter-image]: https://img.shields.io/badge/Gitter-Join%20Chat-blue.svg?style=flat\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/SGrondin/bottleneck.git"
  },
  "scripts": {
    "build": "./scripts/build.sh",
    "compile": "./scripts/build.sh compile",
    "test": "./node_modules/mocha/bin/mocha test/index.js"
  },
  "typings": "bottleneck.d.ts",
  "version": "1.16.0"
}
